{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5383ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\t 0\n",
      "Train-Acc:\t 0.55524\n",
      "Test-Acc:\t 0.61812\n",
      "I:\t 1\n",
      "Train-Acc:\t 0.613\n",
      "Test-Acc:\t 0.67008\n",
      "I:\t 2\n",
      "Train-Acc:\t 0.63912\n",
      "Test-Acc:\t 0.70512\n",
      "I:\t 3\n",
      "Train-Acc:\t 0.66612\n",
      "Test-Acc:\t 0.72616\n",
      "I:\t 4\n",
      "Train-Acc:\t 0.68592\n",
      "Test-Acc:\t 0.74224\n",
      "I:\t 5\n",
      "Train-Acc:\t 0.699\n",
      "Test-Acc:\t 0.7584\n",
      "I:\t 6\n",
      "Train-Acc:\t 0.70916\n",
      "Test-Acc:\t 0.76696\n",
      "I:\t 7\n",
      "Train-Acc:\t 0.72116\n",
      "Test-Acc:\t 0.7718\n",
      "I:\t 8\n",
      "Train-Acc:\t 0.725\n",
      "Test-Acc:\t 0.7762\n",
      "I:\t 9\n",
      "Train-Acc:\t 0.735\n",
      "Test-Acc:\t 0.78392\n",
      "I:\t 10\n",
      "Train-Acc:\t 0.73796\n",
      "Test-Acc:\t 0.78732\n",
      "I:\t 11\n",
      "Train-Acc:\t 0.75008\n",
      "Test-Acc:\t 0.78976\n",
      "I:\t 12\n",
      "Train-Acc:\t 0.75012\n",
      "Test-Acc:\t 0.79356\n",
      "I:\t 13\n",
      "Train-Acc:\t 0.75396\n",
      "Test-Acc:\t 0.79912\n",
      "I:\t 14\n",
      "Train-Acc:\t 0.7584\n",
      "Test-Acc:\t 0.80368\n",
      "I:\t 15\n",
      "Train-Acc:\t 0.76184\n",
      "Test-Acc:\t 0.80324\n",
      "I:\t 16\n",
      "Train-Acc:\t 0.763\n",
      "Test-Acc:\t 0.8058\n",
      "I:\t 17\n",
      "Train-Acc:\t 0.76988\n",
      "Test-Acc:\t 0.80848\n",
      "I:\t 18\n",
      "Train-Acc:\t 0.76992\n",
      "Test-Acc:\t 0.81272\n",
      "I:\t 19\n",
      "Train-Acc:\t 0.77404\n",
      "Test-Acc:\t 0.81436\n",
      "I:\t 20\n",
      "Train-Acc:\t 0.77952\n",
      "Test-Acc:\t 0.81648\n",
      "I:\t 21\n",
      "Train-Acc:\t 0.78464\n",
      "Test-Acc:\t 0.81756\n",
      "I:\t 22\n",
      "Train-Acc:\t 0.78244\n",
      "Test-Acc:\t 0.81992\n",
      "I:\t 23\n",
      "Train-Acc:\t 0.78416\n",
      "Test-Acc:\t 0.8208\n",
      "I:\t 24\n",
      "Train-Acc:\t 0.78544\n",
      "Test-Acc:\t 0.82192\n",
      "I:\t 25\n",
      "Train-Acc:\t 0.78592\n",
      "Test-Acc:\t 0.8226\n",
      "I:\t 26\n",
      "Train-Acc:\t 0.78836\n",
      "Test-Acc:\t 0.8234\n",
      "I:\t 27\n",
      "Train-Acc:\t 0.79184\n",
      "Test-Acc:\t 0.82004\n",
      "I:\t 28\n",
      "Train-Acc:\t 0.7938\n",
      "Test-Acc:\t 0.82564\n",
      "I:\t 29\n",
      "Train-Acc:\t 0.79032\n",
      "Test-Acc:\t 0.82816\n",
      "I:\t 30\n",
      "Train-Acc:\t 0.79156\n",
      "Test-Acc:\t 0.82616\n",
      "I:\t 31\n",
      "Train-Acc:\t 0.79444\n",
      "Test-Acc:\t 0.82944\n",
      "I:\t 32\n",
      "Train-Acc:\t 0.79972\n",
      "Test-Acc:\t 0.8312\n",
      "I:\t 33\n",
      "Train-Acc:\t 0.8002\n",
      "Test-Acc:\t 0.82884\n",
      "I:\t 34\n",
      "Train-Acc:\t 0.79816\n",
      "Test-Acc:\t 0.83184\n",
      "I:\t 35\n",
      "Train-Acc:\t 0.80072\n",
      "Test-Acc:\t 0.83096\n",
      "I:\t 36\n",
      "Train-Acc:\t 0.79804\n",
      "Test-Acc:\t 0.83248\n",
      "I:\t 37\n",
      "Train-Acc:\t 0.80272\n",
      "Test-Acc:\t 0.83332\n",
      "I:\t 38\n",
      "Train-Acc:\t 0.8042\n",
      "Test-Acc:\t 0.83232\n",
      "I:\t 39\n",
      "Train-Acc:\t 0.80308\n",
      "Test-Acc:\t 0.83528\n",
      "I:\t 40\n",
      "Train-Acc:\t 0.80336\n",
      "Test-Acc:\t 0.8344\n",
      "I:\t 41\n",
      "Train-Acc:\t 0.80756\n",
      "Test-Acc:\t 0.83528\n",
      "I:\t 42\n",
      "Train-Acc:\t 0.807\n",
      "Test-Acc:\t 0.83608\n",
      "I:\t 43\n",
      "Train-Acc:\t 0.80752\n",
      "Test-Acc:\t 0.83704\n",
      "I:\t 44\n",
      "Train-Acc:\t 0.80928\n",
      "Test-Acc:\t 0.83732\n",
      "I:\t 45\n",
      "Train-Acc:\t 0.81076\n",
      "Test-Acc:\t 0.83792\n",
      "I:\t 46\n",
      "Train-Acc:\t 0.8104\n",
      "Test-Acc:\t 0.83608\n",
      "I:\t 47\n",
      "Train-Acc:\t 0.81328\n",
      "Test-Acc:\t 0.83796\n",
      "I:\t 48\n",
      "Train-Acc:\t 0.81224\n",
      "Test-Acc:\t 0.8384\n",
      "I:\t 49\n",
      "Train-Acc:\t 0.81112\n",
      "Test-Acc:\t 0.83912\n",
      "I:\t 50\n",
      "Train-Acc:\t 0.81504\n",
      "Test-Acc:\t 0.83828\n",
      "I:\t 51\n",
      "Train-Acc:\t 0.81856\n",
      "Test-Acc:\t 0.83952\n",
      "I:\t 52\n",
      "Train-Acc:\t 0.81436\n",
      "Test-Acc:\t 0.8376\n",
      "I:\t 53\n",
      "Train-Acc:\t 0.8166\n",
      "Test-Acc:\t 0.84144\n",
      "I:\t 54\n",
      "Train-Acc:\t 0.81712\n",
      "Test-Acc:\t 0.83824\n",
      "I:\t 55\n",
      "Train-Acc:\t 0.81748\n",
      "Test-Acc:\t 0.8394\n",
      "I:\t 56\n",
      "Train-Acc:\t 0.8164\n",
      "Test-Acc:\t 0.84036\n",
      "I:\t 57\n",
      "Train-Acc:\t 0.81964\n",
      "Test-Acc:\t 0.84152\n",
      "I:\t 58\n",
      "Train-Acc:\t 0.81996\n",
      "Test-Acc:\t 0.84152\n",
      "I:\t 59\n",
      "Train-Acc:\t 0.81876\n",
      "Test-Acc:\t 0.84252\n",
      "I:\t 60\n",
      "Train-Acc:\t 0.82036\n",
      "Test-Acc:\t 0.8422\n",
      "I:\t 61\n",
      "Train-Acc:\t 0.82116\n",
      "Test-Acc:\t 0.84344\n",
      "I:\t 62\n",
      "Train-Acc:\t 0.8184\n",
      "Test-Acc:\t 0.84256\n",
      "I:\t 63\n",
      "Train-Acc:\t 0.82296\n",
      "Test-Acc:\t 0.843\n",
      "I:\t 64\n",
      "Train-Acc:\t 0.81908\n",
      "Test-Acc:\t 0.8432\n",
      "I:\t 65\n",
      "Train-Acc:\t 0.82596\n",
      "Test-Acc:\t 0.84336\n",
      "I:\t 66\n",
      "Train-Acc:\t 0.82448\n",
      "Test-Acc:\t 0.84308\n",
      "I:\t 67\n",
      "Train-Acc:\t 0.82188\n",
      "Test-Acc:\t 0.84444\n",
      "I:\t 68\n",
      "Train-Acc:\t 0.82504\n",
      "Test-Acc:\t 0.8432\n",
      "I:\t 69\n",
      "Train-Acc:\t 0.8242\n",
      "Test-Acc:\t 0.84512\n",
      "I:\t 70\n",
      "Train-Acc:\t 0.82772\n",
      "Test-Acc:\t 0.84448\n",
      "I:\t 71\n",
      "Train-Acc:\t 0.82628\n",
      "Test-Acc:\t 0.84484\n",
      "I:\t 72\n",
      "Train-Acc:\t 0.82692\n",
      "Test-Acc:\t 0.84508\n",
      "I:\t 73\n",
      "Train-Acc:\t 0.82548\n",
      "Test-Acc:\t 0.84492\n",
      "I:\t 74\n",
      "Train-Acc:\t 0.82748\n",
      "Test-Acc:\t 0.84488\n",
      "I:\t 75\n",
      "Train-Acc:\t 0.82848\n",
      "Test-Acc:\t 0.84564\n",
      "I:\t 76\n",
      "Train-Acc:\t 0.8304\n",
      "Test-Acc:\t 0.84528\n",
      "I:\t 77\n",
      "Train-Acc:\t 0.82884\n",
      "Test-Acc:\t 0.8464\n",
      "I:\t 78\n",
      "Train-Acc:\t 0.8306\n",
      "Test-Acc:\t 0.84604\n",
      "I:\t 79\n",
      "Train-Acc:\t 0.83064\n",
      "Test-Acc:\t 0.84676\n",
      "I:\t 80\n",
      "Train-Acc:\t 0.8276\n",
      "Test-Acc:\t 0.84628\n",
      "I:\t 81\n",
      "Train-Acc:\t 0.83244\n",
      "Test-Acc:\t 0.84544\n",
      "I:\t 82\n",
      "Train-Acc:\t 0.83112\n",
      "Test-Acc:\t 0.84592\n",
      "I:\t 83\n",
      "Train-Acc:\t 0.83344\n",
      "Test-Acc:\t 0.8456\n",
      "I:\t 84\n",
      "Train-Acc:\t 0.83256\n",
      "Test-Acc:\t 0.84672\n",
      "I:\t 85\n",
      "Train-Acc:\t 0.83332\n",
      "Test-Acc:\t 0.84644\n",
      "I:\t 86\n",
      "Train-Acc:\t 0.83544\n",
      "Test-Acc:\t 0.84696\n",
      "I:\t 87\n",
      "Train-Acc:\t 0.83236\n",
      "Test-Acc:\t 0.84732\n",
      "I:\t 88\n",
      "Train-Acc:\t 0.83188\n",
      "Test-Acc:\t 0.84656\n",
      "I:\t 89\n",
      "Train-Acc:\t 0.83524\n",
      "Test-Acc:\t 0.84628\n",
      "I:\t 90\n",
      "Train-Acc:\t 0.83144\n",
      "Test-Acc:\t 0.84788\n",
      "I:\t 91\n",
      "Train-Acc:\t 0.8344\n",
      "Test-Acc:\t 0.84756\n",
      "I:\t 92\n",
      "Train-Acc:\t 0.8378\n",
      "Test-Acc:\t 0.84724\n",
      "I:\t 93\n",
      "Train-Acc:\t 0.83488\n",
      "Test-Acc:\t 0.84644\n",
      "I:\t 94\n",
      "Train-Acc:\t 0.83584\n",
      "Test-Acc:\t 0.84776\n",
      "I:\t 95\n",
      "Train-Acc:\t 0.83624\n",
      "Test-Acc:\t 0.84684\n",
      "I:\t 96\n",
      "Train-Acc:\t 0.83608\n",
      "Test-Acc:\t 0.84572\n",
      "I:\t 97\n",
      "Train-Acc:\t 0.83616\n",
      "Test-Acc:\t 0.84788\n",
      "I:\t 98\n",
      "Train-Acc:\t 0.83712\n",
      "Test-Acc:\t 0.84732\n",
      "I:\t 99\n",
      "Train-Acc:\t 0.83928\n",
      "Test-Acc:\t 0.84772\n",
      "I:\t 100\n",
      "Train-Acc:\t 0.83624\n",
      "Test-Acc:\t 0.84788\n",
      "I:\t 101\n",
      "Train-Acc:\t 0.83768\n",
      "Test-Acc:\t 0.84776\n",
      "I:\t 102\n",
      "Train-Acc:\t 0.83932\n",
      "Test-Acc:\t 0.84704\n",
      "I:\t 103\n",
      "Train-Acc:\t 0.8394\n",
      "Test-Acc:\t 0.84884\n",
      "I:\t 104\n",
      "Train-Acc:\t 0.8386\n",
      "Test-Acc:\t 0.84816\n",
      "I:\t 105\n",
      "Train-Acc:\t 0.837\n",
      "Test-Acc:\t 0.84828\n",
      "I:\t 106\n",
      "Train-Acc:\t 0.83912\n",
      "Test-Acc:\t 0.84872\n",
      "I:\t 107\n",
      "Train-Acc:\t 0.83788\n",
      "Test-Acc:\t 0.84864\n",
      "I:\t 108\n",
      "Train-Acc:\t 0.83756\n",
      "Test-Acc:\t 0.84824\n",
      "I:\t 109\n",
      "Train-Acc:\t 0.84096\n",
      "Test-Acc:\t 0.84852\n",
      "I:\t 110\n",
      "Train-Acc:\t 0.8386\n",
      "Test-Acc:\t 0.84832\n",
      "I:\t 111\n",
      "Train-Acc:\t 0.84064\n",
      "Test-Acc:\t 0.8478\n",
      "I:\t 112\n",
      "Train-Acc:\t 0.84056\n",
      "Test-Acc:\t 0.84808\n",
      "I:\t 113\n",
      "Train-Acc:\t 0.8394\n",
      "Test-Acc:\t 0.84912\n",
      "I:\t 114\n",
      "Train-Acc:\t 0.8416\n",
      "Test-Acc:\t 0.84748\n",
      "I:\t 115\n",
      "Train-Acc:\t 0.84292\n",
      "Test-Acc:\t 0.84976\n",
      "I:\t 116\n",
      "Train-Acc:\t 0.8432\n",
      "Test-Acc:\t 0.8494\n",
      "I:\t 117\n",
      "Train-Acc:\t 0.84144\n",
      "Test-Acc:\t 0.84852\n",
      "I:\t 118\n",
      "Train-Acc:\t 0.84376\n",
      "Test-Acc:\t 0.84824\n",
      "I:\t 119\n",
      "Train-Acc:\t 0.84392\n",
      "Test-Acc:\t 0.84904\n",
      "I:\t 120\n",
      "Train-Acc:\t 0.84152\n",
      "Test-Acc:\t 0.84872\n",
      "I:\t 121\n",
      "Train-Acc:\t 0.8426\n",
      "Test-Acc:\t 0.84896\n",
      "I:\t 122\n",
      "Train-Acc:\t 0.84304\n",
      "Test-Acc:\t 0.84964\n",
      "I:\t 123\n",
      "Train-Acc:\t 0.84168\n",
      "Test-Acc:\t 0.8494\n",
      "I:\t 124\n",
      "Train-Acc:\t 0.84528\n",
      "Test-Acc:\t 0.84948\n",
      "I:\t 125\n",
      "Train-Acc:\t 0.8424\n",
      "Test-Acc:\t 0.85\n",
      "I:\t 126\n",
      "Train-Acc:\t 0.84508\n",
      "Test-Acc:\t 0.84952\n",
      "I:\t 127\n",
      "Train-Acc:\t 0.8416\n",
      "Test-Acc:\t 0.84932\n",
      "I:\t 128\n",
      "Train-Acc:\t 0.8454\n",
      "Test-Acc:\t 0.84912\n",
      "I:\t 129\n",
      "Train-Acc:\t 0.84632\n",
      "Test-Acc:\t 0.84944\n",
      "I:\t 130\n",
      "Train-Acc:\t 0.84604\n",
      "Test-Acc:\t 0.84916\n",
      "I:\t 131\n",
      "Train-Acc:\t 0.84704\n",
      "Test-Acc:\t 0.84988\n",
      "I:\t 132\n",
      "Train-Acc:\t 0.84528\n",
      "Test-Acc:\t 0.84948\n",
      "I:\t 133\n",
      "Train-Acc:\t 0.84736\n",
      "Test-Acc:\t 0.84972\n",
      "I:\t 134\n",
      "Train-Acc:\t 0.8444\n",
      "Test-Acc:\t 0.85\n",
      "I:\t 135\n",
      "Train-Acc:\t 0.84812\n",
      "Test-Acc:\t 0.85072\n",
      "I:\t 136\n",
      "Train-Acc:\t 0.84684\n",
      "Test-Acc:\t 0.84992\n",
      "I:\t 137\n",
      "Train-Acc:\t 0.8454\n",
      "Test-Acc:\t 0.84928\n",
      "I:\t 138\n",
      "Train-Acc:\t 0.84748\n",
      "Test-Acc:\t 0.8494\n",
      "I:\t 139\n",
      "Train-Acc:\t 0.85008\n",
      "Test-Acc:\t 0.8498\n",
      "I:\t 140\n",
      "Train-Acc:\t 0.84536\n",
      "Test-Acc:\t 0.84988\n",
      "I:\t 141\n",
      "Train-Acc:\t 0.84772\n",
      "Test-Acc:\t 0.85\n",
      "I:\t 142\n",
      "Train-Acc:\t 0.84856\n",
      "Test-Acc:\t 0.84976\n",
      "I:\t 143\n",
      "Train-Acc:\t 0.84972\n",
      "Test-Acc:\t 0.85044\n",
      "I:\t 144\n",
      "Train-Acc:\t 0.8476\n",
      "Test-Acc:\t 0.8514\n",
      "I:\t 145\n",
      "Train-Acc:\t 0.84904\n",
      "Test-Acc:\t 0.84928\n",
      "I:\t 146\n",
      "Train-Acc:\t 0.85136\n",
      "Test-Acc:\t 0.85072\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     correct_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mabs\u001b[39m(layer_2[k: k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m y_train[batch_st \u001b[38;5;241m+\u001b[39m k: batch_st \u001b[38;5;241m+\u001b[39m k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     53\u001b[0m layer_2_delta \u001b[38;5;241m=\u001b[39m (y_train[batch_st: batch_end] \u001b[38;5;241m-\u001b[39m layer_2) \u001b[38;5;241m/\u001b[39m (batch_size \u001b[38;5;241m*\u001b[39m layer_2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# !!!!!!!!!\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m layer_1_delta \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_2_delta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_1_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m relu2deriv(layer_1)\n\u001b[0;32m     55\u001b[0m layer_1_delta \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m dropout_mask\n\u001b[0;32m     56\u001b[0m error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(layer_2_delta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()\n",
    "amount_of_train_words = 1000\n",
    "y_train = y_train.reshape((len(y_test), 1))\n",
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "words_indexes = imdb.get_word_index()\n",
    "rev_words_indexes = dict()\n",
    "for word, ind in words_indexes.items():\n",
    "    rev_words_indexes[ind] = word\n",
    "    \n",
    "amount_of_examples = len(x_train) #25000\n",
    "input_feedback = np.zeros((amount_of_examples, amount_of_train_words))\n",
    "for ex in range(amount_of_examples):\n",
    "    for ind in x_train[ex]:\n",
    "        if ind < amount_of_train_words:\n",
    "            input_feedback[ex][ind] = 1\n",
    "            \n",
    "\n",
    "test_feedback = np.zeros((len(x_test), amount_of_train_words))\n",
    "for ex in range(len(x_test)):\n",
    "    for ind in x_test[ex]:\n",
    "        if ind < amount_of_train_words:\n",
    "            test_feedback[ex][ind] = 1\n",
    "\n",
    "\n",
    "            \n",
    "alpha, iterations, hidden_size = (100, 300, 100)\n",
    "batch_size = 500\n",
    "weights_0_1 = 0.2 * np.random.random((amount_of_train_words, hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n",
    "\n",
    "relu = lambda x: (x > 0) * x\n",
    "relu2deriv = lambda x: (x > 0)\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "for j in range(iterations):\n",
    "    correct_cnt, error = 0, 0.0\n",
    "    for i in range(len(input_feedback) // batch_size):\n",
    "        batch_st, batch_end = (i * batch_size, (i + 1) * batch_size)\n",
    "        layer_0 = input_feedback[batch_st: batch_end]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        \n",
    "#         print(y_train[batch_st: batch_end].shape, len(input_feedback) // batch_size)\n",
    "        for k in range(batch_size):\n",
    "#             print(layer_2[k: k + 1], y_train[batch_st + k: batch_st + k + 1])\n",
    "            correct_cnt += int(abs(layer_2[k: k + 1] - y_train[batch_st + k: batch_st + k + 1]) < 0.5)\n",
    "        \n",
    "        \n",
    "        layer_2_delta = (y_train[batch_st: batch_end] - layer_2) / (batch_size * layer_2.shape[0]) # !!!!!!!!!\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        error += np.sum(layer_2_delta**2, axis=0)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta) # !!!!!!!!!!\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta) # !!!!!!!!!!\n",
    "#         print('@ ', i)\n",
    "    test_correct_cnt = 0\n",
    "    for i in range(len(test_feedback)):\n",
    "        layer_0 = test_feedback[i: i + 1]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        test_correct_cnt += int(abs(layer_2 - y_test[i: i + 1]) < 0.5)\n",
    "    print('I:\\t', j)\n",
    "    print('Train-Acc:\\t', correct_cnt / float(len(input_feedback)))\n",
    "    print('Test-Acc:\\t', test_correct_cnt / len(test_feedback))\n",
    "        \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fd65ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 63, 218, 10, 25, 329, 9, 108, 208, 2, 172, 783, 312, 146, 13, 5146]\n",
      "[[0.21275535]]\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = 'That was really interesting I have read it many times and every minute during watching was astonishing'\n",
    "l = []\n",
    "for unit in sentence.lower().split():\n",
    "    if unit in words_indexes.keys():\n",
    "        l.append(words_indexes[unit])\n",
    "    else:\n",
    "        l.append(0)\n",
    "        \n",
    "# l = x_test[4]\n",
    "hlayer_0 = np.zeros((1, amount_of_train_words))\n",
    "for ind in l:\n",
    "    if ind < amount_of_train_words:\n",
    "        hlayer_0[0][ind] = 1\n",
    "\n",
    "# print(hlayer_0)\n",
    "hlayer_1 = relu(hlayer_0.dot(weights_0_1))\n",
    "hlayer_2 = hlayer_1.dot(weights_1_2)\n",
    "print(l)\n",
    "print(hlayer_2)\n",
    "if hlayer_2 < 0.5:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c61fffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077] [1]\n",
      "the as you world's is quite br mankind most that quest are chase to being quickly of little it time hell to plot br of something long put are of every place this consequence council of interplay storytelling being nasty not of you warren in is failed club i i of films pay so sequences mightily film okay uses to received wackiness if time done for room sugar viewer as cartoon of gives to forgettable br be because many these of reflection sugar contained gives it wreck scene to more was two when had find as you another it of themselves probably who interplay storytelling if itself by br about 1950's films not would effects that her box to miike for if hero close seek end is very together movie of wheel got say kong sugar fred close bore there is playing lot of scriptures pan place trilogy of lacks br of their time much this men as on it is telling program br silliness okay orientation to frustration at corner rawlins she of sequences to political clearly in of drugs keep guy i i was throwing room sugar as it by br be plot many for occasionally film verge boyfriend difficult kid as you it failed not if gerard to if woman in launching is police fi spooky or of self what have pretty in can so suit you good 2 which why super as it main of my i i  if time screenplay in same this remember assured have action one in realistic that better of lessons "
     ]
    }
   ],
   "source": [
    "print(x_test[1], y_test[1])\n",
    "for i in x_test[1]:\n",
    "    print(rev_words_indexes[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e65f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
