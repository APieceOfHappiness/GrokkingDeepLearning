{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5383ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\t 0\n",
      "Train-Acc:\t 0.50916\n",
      "Test-Acc:\t 0.54948\n",
      "I:\t 1\n",
      "Train-Acc:\t 0.59252\n",
      "Test-Acc:\t 0.67268\n",
      "I:\t 2\n",
      "Train-Acc:\t 0.673\n",
      "Test-Acc:\t 0.75132\n",
      "I:\t 3\n",
      "Train-Acc:\t 0.72876\n",
      "Test-Acc:\t 0.78044\n",
      "I:\t 4\n",
      "Train-Acc:\t 0.76084\n",
      "Test-Acc:\t 0.79452\n",
      "I:\t 5\n",
      "Train-Acc:\t 0.77664\n",
      "Test-Acc:\t 0.80452\n",
      "I:\t 6\n",
      "Train-Acc:\t 0.79164\n",
      "Test-Acc:\t 0.81336\n",
      "I:\t 7\n",
      "Train-Acc:\t 0.79924\n",
      "Test-Acc:\t 0.81936\n",
      "I:\t 8\n",
      "Train-Acc:\t 0.80556\n",
      "Test-Acc:\t 0.82328\n",
      "I:\t 9\n",
      "Train-Acc:\t 0.8116\n",
      "Test-Acc:\t 0.82848\n",
      "I:\t 10\n",
      "Train-Acc:\t 0.81376\n",
      "Test-Acc:\t 0.83148\n",
      "I:\t 11\n",
      "Train-Acc:\t 0.8196\n",
      "Test-Acc:\t 0.83428\n",
      "I:\t 12\n",
      "Train-Acc:\t 0.82368\n",
      "Test-Acc:\t 0.8364\n",
      "I:\t 13\n",
      "Train-Acc:\t 0.82656\n",
      "Test-Acc:\t 0.83864\n",
      "I:\t 14\n",
      "Train-Acc:\t 0.8256\n",
      "Test-Acc:\t 0.84092\n",
      "I:\t 15\n",
      "Train-Acc:\t 0.83168\n",
      "Test-Acc:\t 0.84288\n",
      "I:\t 16\n",
      "Train-Acc:\t 0.82848\n",
      "Test-Acc:\t 0.8434\n",
      "I:\t 17\n",
      "Train-Acc:\t 0.8312\n",
      "Test-Acc:\t 0.84412\n",
      "I:\t 18\n",
      "Train-Acc:\t 0.83392\n",
      "Test-Acc:\t 0.84568\n",
      "I:\t 19\n",
      "Train-Acc:\t 0.83808\n",
      "Test-Acc:\t 0.84632\n",
      "I:\t 20\n",
      "Train-Acc:\t 0.83656\n",
      "Test-Acc:\t 0.84672\n",
      "I:\t 21\n",
      "Train-Acc:\t 0.84004\n",
      "Test-Acc:\t 0.84768\n",
      "I:\t 22\n",
      "Train-Acc:\t 0.84056\n",
      "Test-Acc:\t 0.84844\n",
      "I:\t 23\n",
      "Train-Acc:\t 0.84072\n",
      "Test-Acc:\t 0.84884\n",
      "I:\t 24\n",
      "Train-Acc:\t 0.84172\n",
      "Test-Acc:\t 0.849\n",
      "I:\t 25\n",
      "Train-Acc:\t 0.84548\n",
      "Test-Acc:\t 0.85056\n",
      "I:\t 26\n",
      "Train-Acc:\t 0.8412\n",
      "Test-Acc:\t 0.85164\n",
      "I:\t 27\n",
      "Train-Acc:\t 0.844\n",
      "Test-Acc:\t 0.85128\n",
      "I:\t 28\n",
      "Train-Acc:\t 0.84544\n",
      "Test-Acc:\t 0.85264\n",
      "I:\t 29\n",
      "Train-Acc:\t 0.84772\n",
      "Test-Acc:\t 0.85312\n",
      "I:\t 30\n",
      "Train-Acc:\t 0.84844\n",
      "Test-Acc:\t 0.85304\n",
      "I:\t 31\n",
      "Train-Acc:\t 0.84528\n",
      "Test-Acc:\t 0.85356\n",
      "I:\t 32\n",
      "Train-Acc:\t 0.84628\n",
      "Test-Acc:\t 0.85388\n",
      "I:\t 33\n",
      "Train-Acc:\t 0.84832\n",
      "Test-Acc:\t 0.85332\n",
      "I:\t 34\n",
      "Train-Acc:\t 0.847\n",
      "Test-Acc:\t 0.85356\n",
      "I:\t 35\n",
      "Train-Acc:\t 0.84956\n",
      "Test-Acc:\t 0.85364\n",
      "I:\t 36\n",
      "Train-Acc:\t 0.84976\n",
      "Test-Acc:\t 0.85416\n",
      "I:\t 37\n",
      "Train-Acc:\t 0.85224\n",
      "Test-Acc:\t 0.85468\n",
      "I:\t 38\n",
      "Train-Acc:\t 0.85068\n",
      "Test-Acc:\t 0.85452\n",
      "I:\t 39\n",
      "Train-Acc:\t 0.85152\n",
      "Test-Acc:\t 0.85416\n",
      "I:\t 40\n",
      "Train-Acc:\t 0.85064\n",
      "Test-Acc:\t 0.85448\n",
      "I:\t 41\n",
      "Train-Acc:\t 0.85072\n",
      "Test-Acc:\t 0.8552\n",
      "I:\t 42\n",
      "Train-Acc:\t 0.8524\n",
      "Test-Acc:\t 0.85468\n",
      "I:\t 43\n",
      "Train-Acc:\t 0.85392\n",
      "Test-Acc:\t 0.85468\n",
      "I:\t 44\n",
      "Train-Acc:\t 0.85364\n",
      "Test-Acc:\t 0.85508\n",
      "I:\t 45\n",
      "Train-Acc:\t 0.85516\n",
      "Test-Acc:\t 0.85484\n",
      "I:\t 46\n",
      "Train-Acc:\t 0.8552\n",
      "Test-Acc:\t 0.85512\n",
      "I:\t 47\n",
      "Train-Acc:\t 0.855\n",
      "Test-Acc:\t 0.85488\n",
      "I:\t 48\n",
      "Train-Acc:\t 0.8548\n",
      "Test-Acc:\t 0.85508\n",
      "I:\t 49\n",
      "Train-Acc:\t 0.85508\n",
      "Test-Acc:\t 0.85496\n",
      "I:\t 50\n",
      "Train-Acc:\t 0.8562\n",
      "Test-Acc:\t 0.85528\n",
      "I:\t 51\n",
      "Train-Acc:\t 0.85452\n",
      "Test-Acc:\t 0.85644\n",
      "I:\t 52\n",
      "Train-Acc:\t 0.85612\n",
      "Test-Acc:\t 0.85524\n",
      "I:\t 53\n",
      "Train-Acc:\t 0.85748\n",
      "Test-Acc:\t 0.8562\n",
      "I:\t 54\n",
      "Train-Acc:\t 0.85664\n",
      "Test-Acc:\t 0.85424\n",
      "I:\t 55\n",
      "Train-Acc:\t 0.85716\n",
      "Test-Acc:\t 0.85544\n",
      "I:\t 56\n",
      "Train-Acc:\t 0.85712\n",
      "Test-Acc:\t 0.85572\n",
      "I:\t 57\n",
      "Train-Acc:\t 0.85892\n",
      "Test-Acc:\t 0.85512\n",
      "I:\t 58\n",
      "Train-Acc:\t 0.85516\n",
      "Test-Acc:\t 0.85464\n",
      "I:\t 59\n",
      "Train-Acc:\t 0.85856\n",
      "Test-Acc:\t 0.85456\n",
      "I:\t 60\n",
      "Train-Acc:\t 0.85836\n",
      "Test-Acc:\t 0.856\n",
      "I:\t 61\n",
      "Train-Acc:\t 0.85692\n",
      "Test-Acc:\t 0.85496\n",
      "I:\t 62\n",
      "Train-Acc:\t 0.85684\n",
      "Test-Acc:\t 0.85576\n",
      "I:\t 63\n",
      "Train-Acc:\t 0.857\n",
      "Test-Acc:\t 0.85456\n",
      "I:\t 64\n",
      "Train-Acc:\t 0.85844\n",
      "Test-Acc:\t 0.85612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()\n",
    "amount_of_train_words = 1000\n",
    "y_train = y_train.reshape((len(y_test), 1))\n",
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "words_indexes = imdb.get_word_index()\n",
    "rev_words_indexes = dict()\n",
    "for word, ind in words_indexes.items():\n",
    "    rev_words_indexes[ind] = word\n",
    "    \n",
    "amount_of_examples = len(x_train) #25000\n",
    "input_feedback = np.zeros((amount_of_examples, amount_of_train_words))\n",
    "for ex in range(amount_of_examples):\n",
    "    for ind in x_train[ex]:\n",
    "        if ind < amount_of_train_words:\n",
    "            input_feedback[ex][ind] = 1\n",
    "            \n",
    "\n",
    "test_feedback = np.zeros((len(x_test), amount_of_train_words))\n",
    "for ex in range(len(x_test)):\n",
    "    for ind in x_test[ex]:\n",
    "        if ind < amount_of_train_words:\n",
    "            test_feedback[ex][ind] = 1\n",
    "\n",
    "\n",
    "            \n",
    "alpha, iterations, hidden_size = (20, 300, 100)\n",
    "batch_size = 500\n",
    "weights_0_1 = 0.02 * np.random.random((amount_of_train_words, hidden_size)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n",
    "\n",
    "relu = lambda x: (x > 0) * x\n",
    "relu2deriv = lambda x: (x > 0)\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "for j in range(iterations):\n",
    "    correct_cnt, error = 0, 0.0\n",
    "    for i in range(len(input_feedback) // batch_size):\n",
    "        batch_st, batch_end = (i * batch_size, (i + 1) * batch_size)\n",
    "        layer_0 = input_feedback[batch_st: batch_end]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        \n",
    "#         print(y_train[batch_st: batch_end].shape, len(input_feedback) // batch_size)\n",
    "        for k in range(batch_size):\n",
    "#             print(layer_2[k: k + 1], y_train[batch_st + k: batch_st + k + 1])\n",
    "            correct_cnt += int(abs(layer_2[k: k + 1] - y_train[batch_st + k: batch_st + k + 1]) < 0.5)\n",
    "        \n",
    "        \n",
    "        layer_2_delta = (y_train[batch_st: batch_end] - layer_2) / (batch_size * layer_2.shape[0]) # !!!!!!!!!\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        error += np.sum(layer_2_delta**2, axis=0)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta) # !!!!!!!!!!\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta) # !!!!!!!!!!\n",
    "#         print('@ ', i)\n",
    "    test_correct_cnt = 0\n",
    "    for i in range(len(test_feedback)):\n",
    "        layer_0 = test_feedback[i: i + 1]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        test_correct_cnt += int(abs(layer_2 - y_test[i: i + 1]) < 0.5)\n",
    "    print('I:\\t', j)\n",
    "    print('Train-Acc:\\t', correct_cnt / float(len(input_feedback)))\n",
    "    print('Test-Acc:\\t', test_correct_cnt / len(test_feedback))\n",
    "        \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fd65ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 63, 218, 10, 25, 329, 9, 108, 208, 2, 172, 783, 312, 146, 13, 5146]\n",
      "[[0.21275535]]\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = 'That was really interesting I have read it many times and every minute during watching was astonishing'\n",
    "l = []\n",
    "for unit in sentence.lower().split():\n",
    "    if unit in words_indexes.keys():\n",
    "        l.append(words_indexes[unit])\n",
    "    else:\n",
    "        l.append(0)\n",
    "        \n",
    "# l = x_test[4]\n",
    "hlayer_0 = np.zeros((1, amount_of_train_words))\n",
    "for ind in l:\n",
    "    if ind < amount_of_train_words:\n",
    "        hlayer_0[0][ind] = 1\n",
    "\n",
    "# print(hlayer_0)\n",
    "hlayer_1 = relu(hlayer_0.dot(weights_0_1))\n",
    "hlayer_2 = hlayer_1.dot(weights_1_2)\n",
    "print(l)\n",
    "print(hlayer_2)\n",
    "if hlayer_2 < 0.5:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c61fffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077] [1]\n",
      "the as you world's is quite br mankind most that quest are chase to being quickly of little it time hell to plot br of something long put are of every place this consequence council of interplay storytelling being nasty not of you warren in is failed club i i of films pay so sequences mightily film okay uses to received wackiness if time done for room sugar viewer as cartoon of gives to forgettable br be because many these of reflection sugar contained gives it wreck scene to more was two when had find as you another it of themselves probably who interplay storytelling if itself by br about 1950's films not would effects that her box to miike for if hero close seek end is very together movie of wheel got say kong sugar fred close bore there is playing lot of scriptures pan place trilogy of lacks br of their time much this men as on it is telling program br silliness okay orientation to frustration at corner rawlins she of sequences to political clearly in of drugs keep guy i i was throwing room sugar as it by br be plot many for occasionally film verge boyfriend difficult kid as you it failed not if gerard to if woman in launching is police fi spooky or of self what have pretty in can so suit you good 2 which why super as it main of my i i Â– if time screenplay in same this remember assured have action one in realistic that better of lessons "
     ]
    }
   ],
   "source": [
    "print(x_test[1], y_test[1])\n",
    "for i in x_test[1]:\n",
    "    print(rev_words_indexes[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e65f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
