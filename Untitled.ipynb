{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79cb0303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  0\n",
      "train_correct:  0.089\n",
      "test_correct:   0.0806\n",
      "----------------------------------------------------\n",
      "I:  10\n",
      "train_correct:  0.163\n",
      "test_correct:   0.2187\n",
      "----------------------------------------------------\n",
      "I:  20\n",
      "train_correct:  0.316\n",
      "test_correct:   0.4167\n",
      "----------------------------------------------------\n",
      "I:  30\n",
      "train_correct:  0.407\n",
      "test_correct:   0.5306\n",
      "----------------------------------------------------\n",
      "I:  40\n",
      "train_correct:  0.517\n",
      "test_correct:   0.5863\n",
      "----------------------------------------------------\n",
      "I:  50\n",
      "train_correct:  0.567\n",
      "test_correct:   0.6194\n",
      "----------------------------------------------------\n",
      "I:  60\n",
      "train_correct:  0.628\n",
      "test_correct:   0.6385\n",
      "----------------------------------------------------\n",
      "I:  70\n",
      "train_correct:  0.643\n",
      "test_correct:   0.6517\n",
      "----------------------------------------------------\n",
      "I:  80\n",
      "train_correct:  0.663\n",
      "test_correct:   0.6587\n",
      "----------------------------------------------------\n",
      "I:  90\n",
      "train_correct:  0.691\n",
      "test_correct:   0.6637\n",
      "----------------------------------------------------\n",
      "I:  100\n",
      "train_correct:  0.696\n",
      "test_correct:   0.6668\n",
      "----------------------------------------------------\n",
      "I:  110\n",
      "train_correct:  0.711\n",
      "test_correct:   0.6712\n",
      "----------------------------------------------------\n",
      "I:  120\n",
      "train_correct:  0.696\n",
      "test_correct:   0.6743\n",
      "----------------------------------------------------\n",
      "I:  130\n",
      "train_correct:  0.709\n",
      "test_correct:   0.6787\n",
      "----------------------------------------------------\n",
      "I:  140\n",
      "train_correct:  0.722\n",
      "test_correct:   0.6819\n",
      "----------------------------------------------------\n",
      "I:  150\n",
      "train_correct:  0.727\n",
      "test_correct:   0.6826\n",
      "----------------------------------------------------\n",
      "I:  160\n",
      "train_correct:  0.723\n",
      "test_correct:   0.6839\n",
      "----------------------------------------------------\n",
      "I:  170\n",
      "train_correct:  0.721\n",
      "test_correct:   0.6848\n",
      "----------------------------------------------------\n",
      "I:  180\n",
      "train_correct:  0.721\n",
      "test_correct:   0.6845\n",
      "----------------------------------------------------\n",
      "I:  190\n",
      "train_correct:  0.712\n",
      "test_correct:   0.6851\n",
      "----------------------------------------------------\n",
      "I:  200\n",
      "train_correct:  0.716\n",
      "test_correct:   0.6859\n",
      "----------------------------------------------------\n",
      "I:  210\n",
      "train_correct:  0.714\n",
      "test_correct:   0.6872\n",
      "----------------------------------------------------\n",
      "I:  220\n",
      "train_correct:  0.711\n",
      "test_correct:   0.6884\n",
      "----------------------------------------------------\n",
      "I:  230\n",
      "train_correct:  0.734\n",
      "test_correct:   0.6893\n",
      "----------------------------------------------------\n",
      "I:  240\n",
      "train_correct:  0.731\n",
      "test_correct:   0.69\n",
      "----------------------------------------------------\n",
      "I:  250\n",
      "train_correct:  0.723\n",
      "test_correct:   0.6904\n",
      "----------------------------------------------------\n",
      "I:  260\n",
      "train_correct:  0.74\n",
      "test_correct:   0.6902\n",
      "----------------------------------------------------\n",
      "I:  270\n",
      "train_correct:  0.724\n",
      "test_correct:   0.6909\n",
      "----------------------------------------------------\n",
      "I:  280\n",
      "train_correct:  0.725\n",
      "test_correct:   0.6922\n",
      "----------------------------------------------------\n",
      "I:  290\n",
      "train_correct:  0.718\n",
      "test_correct:   0.6928\n",
      "----------------------------------------------------\n",
      "I:  300\n",
      "train_correct:  0.715\n",
      "test_correct:   0.6943\n",
      "----------------------------------------------------\n",
      "I:  310\n",
      "train_correct:  0.734\n",
      "test_correct:   0.6948\n",
      "----------------------------------------------------\n",
      "I:  320\n",
      "train_correct:  0.73\n",
      "test_correct:   0.6951\n",
      "----------------------------------------------------\n",
      "I:  330\n",
      "train_correct:  0.733\n",
      "test_correct:   0.6957\n",
      "----------------------------------------------------\n",
      "I:  340\n",
      "train_correct:  0.728\n",
      "test_correct:   0.6974\n",
      "----------------------------------------------------\n",
      "I:  350\n",
      "train_correct:  0.734\n",
      "test_correct:   0.6989\n",
      "----------------------------------------------------\n",
      "I:  360\n",
      "train_correct:  0.736\n",
      "test_correct:   0.6989\n",
      "----------------------------------------------------\n",
      "I:  370\n",
      "train_correct:  0.721\n",
      "test_correct:   0.6994\n",
      "----------------------------------------------------\n",
      "I:  380\n",
      "train_correct:  0.72\n",
      "test_correct:   0.7001\n",
      "----------------------------------------------------\n",
      "I:  390\n",
      "train_correct:  0.727\n",
      "test_correct:   0.7004\n",
      "----------------------------------------------------\n",
      "I:  400\n",
      "train_correct:  0.734\n",
      "test_correct:   0.7026\n",
      "----------------------------------------------------\n",
      "I:  410\n",
      "train_correct:  0.732\n",
      "test_correct:   0.7033\n",
      "----------------------------------------------------\n",
      "I:  420\n",
      "train_correct:  0.737\n",
      "test_correct:   0.7047\n",
      "----------------------------------------------------\n",
      "I:  430\n",
      "train_correct:  0.732\n",
      "test_correct:   0.7057\n",
      "----------------------------------------------------\n",
      "I:  440\n",
      "train_correct:  0.734\n",
      "test_correct:   0.7072\n",
      "----------------------------------------------------\n",
      "I:  450\n",
      "train_correct:  0.75\n",
      "test_correct:   0.708\n",
      "----------------------------------------------------\n",
      "I:  460\n",
      "train_correct:  0.74\n",
      "test_correct:   0.7092\n",
      "----------------------------------------------------\n",
      "I:  470\n",
      "train_correct:  0.747\n",
      "test_correct:   0.7103\n",
      "----------------------------------------------------\n",
      "I:  480\n",
      "train_correct:  0.743\n",
      "test_correct:   0.7116\n",
      "----------------------------------------------------\n",
      "I:  490\n",
      "train_correct:  0.746\n",
      "test_correct:   0.7129\n",
      "----------------------------------------------------\n",
      "I:  500\n",
      "train_correct:  0.747\n",
      "test_correct:   0.716\n",
      "----------------------------------------------------\n",
      "I:  510\n",
      "train_correct:  0.742\n",
      "test_correct:   0.7173\n",
      "----------------------------------------------------\n",
      "I:  520\n",
      "train_correct:  0.752\n",
      "test_correct:   0.7179\n",
      "----------------------------------------------------\n",
      "I:  530\n",
      "train_correct:  0.753\n",
      "test_correct:   0.7196\n",
      "----------------------------------------------------\n",
      "I:  540\n",
      "train_correct:  0.748\n",
      "test_correct:   0.7211\n",
      "----------------------------------------------------\n",
      "I:  550\n",
      "train_correct:  0.755\n",
      "test_correct:   0.7228\n",
      "----------------------------------------------------\n",
      "I:  560\n",
      "train_correct:  0.756\n",
      "test_correct:   0.7242\n",
      "----------------------------------------------------\n",
      "I:  570\n",
      "train_correct:  0.76\n",
      "test_correct:   0.7255\n",
      "----------------------------------------------------\n",
      "I:  580\n",
      "train_correct:  0.76\n",
      "test_correct:   0.7272\n",
      "----------------------------------------------------\n",
      "I:  590\n",
      "train_correct:  0.759\n",
      "test_correct:   0.729\n",
      "----------------------------------------------------\n",
      "I:  600\n",
      "train_correct:  0.765\n",
      "test_correct:   0.7302\n",
      "----------------------------------------------------\n",
      "I:  610\n",
      "train_correct:  0.758\n",
      "test_correct:   0.7322\n",
      "----------------------------------------------------\n",
      "I:  620\n",
      "train_correct:  0.769\n",
      "test_correct:   0.7336\n",
      "----------------------------------------------------\n",
      "I:  630\n",
      "train_correct:  0.754\n",
      "test_correct:   0.7347\n",
      "----------------------------------------------------\n",
      "I:  640\n",
      "train_correct:  0.765\n",
      "test_correct:   0.737\n",
      "----------------------------------------------------\n",
      "I:  650\n",
      "train_correct:  0.766\n",
      "test_correct:   0.74\n",
      "----------------------------------------------------\n",
      "I:  660\n",
      "train_correct:  0.775\n",
      "test_correct:   0.7415\n",
      "----------------------------------------------------\n",
      "I:  670\n",
      "train_correct:  0.778\n",
      "test_correct:   0.744\n",
      "----------------------------------------------------\n",
      "I:  680\n",
      "train_correct:  0.773\n",
      "test_correct:   0.7455\n",
      "----------------------------------------------------\n",
      "I:  690\n",
      "train_correct:  0.778\n",
      "test_correct:   0.7474\n",
      "----------------------------------------------------\n",
      "I:  700\n",
      "train_correct:  0.785\n",
      "test_correct:   0.7491\n",
      "----------------------------------------------------\n",
      "I:  710\n",
      "train_correct:  0.783\n",
      "test_correct:   0.7509\n",
      "----------------------------------------------------\n",
      "I:  720\n",
      "train_correct:  0.782\n",
      "test_correct:   0.7521\n",
      "----------------------------------------------------\n",
      "I:  730\n",
      "train_correct:  0.784\n",
      "test_correct:   0.7536\n",
      "----------------------------------------------------\n",
      "I:  740\n",
      "train_correct:  0.785\n",
      "test_correct:   0.7558\n",
      "----------------------------------------------------\n",
      "I:  750\n",
      "train_correct:  0.795\n",
      "test_correct:   0.7579\n",
      "----------------------------------------------------\n",
      "I:  760\n",
      "train_correct:  0.792\n",
      "test_correct:   0.7593\n",
      "----------------------------------------------------\n",
      "I:  770\n",
      "train_correct:  0.787\n",
      "test_correct:   0.7612\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  780\n",
      "train_correct:  0.797\n",
      "test_correct:   0.7623\n",
      "----------------------------------------------------\n",
      "I:  790\n",
      "train_correct:  0.785\n",
      "test_correct:   0.7642\n",
      "----------------------------------------------------\n",
      "I:  800\n",
      "train_correct:  0.799\n",
      "test_correct:   0.7651\n",
      "----------------------------------------------------\n",
      "I:  810\n",
      "train_correct:  0.796\n",
      "test_correct:   0.7662\n",
      "----------------------------------------------------\n",
      "I:  820\n",
      "train_correct:  0.807\n",
      "test_correct:   0.7679\n",
      "----------------------------------------------------\n",
      "I:  830\n",
      "train_correct:  0.804\n",
      "test_correct:   0.7698\n",
      "----------------------------------------------------\n",
      "I:  840\n",
      "train_correct:  0.802\n",
      "test_correct:   0.7718\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     layer_1 \u001b[38;5;241m=\u001b[39m tanh(layer_0\u001b[38;5;241m.\u001b[39mdot(weights_0_1))\n\u001b[0;32m     64\u001b[0m     layer_2 \u001b[38;5;241m=\u001b[39m layer_1\u001b[38;5;241m.\u001b[39mdot(weights_1_2)\n\u001b[1;32m---> 65\u001b[0m     test_correct_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_lab[i: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI: \u001b[39m\u001b[38;5;124m'\u001b[39m, j)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HELP\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HELP\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = (x_train[:1000].reshape(1000, 28 * 28) / 255, y_train[:1000])\n",
    "\n",
    "temp = np.zeros((len(labels),10))\n",
    "for i, l in enumerate(labels):\n",
    "    temp[i][l] = 1\n",
    "labels = temp\n",
    "\n",
    "test_im = x_test.reshape(len(x_test), 28 * 28) / 255\n",
    "temp = np.zeros((len(test_im), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    temp[i][l] = 1\n",
    "test_lab = temp\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(x):\n",
    "    return 1 - x**2\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "alpha, pixels_per_image, hidden_size = (0.1, 28 * 28, 100)\n",
    "iterations, num_labels = (10000, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.02 * np.random.random((pixels_per_image, hidden_size)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_st, batch_end = ((i * batch_size), ((i + 1) * batch_size))#!!!!!!!\n",
    "        layer_0 = images[batch_st: batch_end]\n",
    "        layer_1 = tanh(layer_0.dot(weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(layer_1.dot(weights_1_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k: k + 1]) == np.argmax(labels[batch_st + k: batch_st + k + 1]))\n",
    "        \n",
    "        layer_2_delta = (labels[batch_st: batch_end] - layer_2) / batch_size / layer_2.shape[0]#!!!!!!!!!!!!!\n",
    "#         print(layer_2_delta.shape, layer_2.shape)\n",
    "#         break\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "#     break\n",
    "    test_correct_cnt = 0\n",
    "    for i in range(len(test_im)):\n",
    "        layer_0 = test_im[i: i + 1]\n",
    "        layer_1 = tanh(layer_0.dot(weights_0_1))\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_lab[i: i + 1]))\n",
    "    \n",
    "    if j % 10 == 0:\n",
    "        print('I: ', j)\n",
    "        print('train_correct: ', correct_cnt / len(labels))\n",
    "        print('test_correct:  ', test_correct_cnt / len(test_lab))\n",
    "        print('----------------------------------------------------')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "79403ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  0\n",
      "train_correct:  0.119\n",
      "test_correct:   0.2438\n",
      "----------------------------------------------------\n",
      "I:  10\n",
      "train_correct:  0.654\n",
      "test_correct:   0.6962\n",
      "----------------------------------------------------\n",
      "I:  20\n",
      "train_correct:  0.754\n",
      "test_correct:   0.7423\n",
      "----------------------------------------------------\n",
      "I:  30\n",
      "train_correct:  0.78\n",
      "test_correct:   0.766\n",
      "----------------------------------------------------\n",
      "I:  40\n",
      "train_correct:  0.81\n",
      "test_correct:   0.7854\n",
      "----------------------------------------------------\n",
      "I:  50\n",
      "train_correct:  0.829\n",
      "test_correct:   0.7969\n",
      "----------------------------------------------------\n",
      "I:  60\n",
      "train_correct:  0.828\n",
      "test_correct:   0.8052\n",
      "----------------------------------------------------\n",
      "I:  70\n",
      "train_correct:  0.847\n",
      "test_correct:   0.8122\n",
      "----------------------------------------------------\n",
      "I:  80\n",
      "train_correct:  0.862\n",
      "test_correct:   0.8176\n",
      "----------------------------------------------------\n",
      "I:  90\n",
      "train_correct:  0.863\n",
      "test_correct:   0.8227\n",
      "----------------------------------------------------\n",
      "I:  100\n",
      "train_correct:  0.876\n",
      "test_correct:   0.8248\n",
      "----------------------------------------------------\n",
      "I:  110\n",
      "train_correct:  0.878\n",
      "test_correct:   0.8277\n",
      "----------------------------------------------------\n",
      "I:  120\n",
      "train_correct:  0.875\n",
      "test_correct:   0.8292\n",
      "----------------------------------------------------\n",
      "I:  130\n",
      "train_correct:  0.891\n",
      "test_correct:   0.8314\n",
      "----------------------------------------------------\n",
      "I:  140\n",
      "train_correct:  0.883\n",
      "test_correct:   0.8345\n",
      "----------------------------------------------------\n",
      "I:  150\n",
      "train_correct:  0.903\n",
      "test_correct:   0.8364\n",
      "----------------------------------------------------\n",
      "I:  160\n",
      "train_correct:  0.902\n",
      "test_correct:   0.8394\n",
      "----------------------------------------------------\n",
      "I:  170\n",
      "train_correct:  0.903\n",
      "test_correct:   0.8403\n",
      "----------------------------------------------------\n",
      "I:  180\n",
      "train_correct:  0.914\n",
      "test_correct:   0.8423\n",
      "----------------------------------------------------\n",
      "I:  190\n",
      "train_correct:  0.909\n",
      "test_correct:   0.843\n",
      "----------------------------------------------------\n",
      "I:  200\n",
      "train_correct:  0.915\n",
      "test_correct:   0.8442\n",
      "----------------------------------------------------\n",
      "I:  210\n",
      "train_correct:  0.926\n",
      "test_correct:   0.8448\n",
      "----------------------------------------------------\n",
      "I:  220\n",
      "train_correct:  0.919\n",
      "test_correct:   0.8459\n",
      "----------------------------------------------------\n",
      "I:  230\n",
      "train_correct:  0.933\n",
      "test_correct:   0.8467\n",
      "----------------------------------------------------\n",
      "I:  240\n",
      "train_correct:  0.923\n",
      "test_correct:   0.8491\n",
      "----------------------------------------------------\n",
      "I:  250\n",
      "train_correct:  0.938\n",
      "test_correct:   0.8488\n",
      "----------------------------------------------------\n",
      "I:  260\n",
      "train_correct:  0.936\n",
      "test_correct:   0.851\n",
      "----------------------------------------------------\n",
      "I:  270\n",
      "train_correct:  0.934\n",
      "test_correct:   0.8513\n",
      "----------------------------------------------------\n",
      "I:  280\n",
      "train_correct:  0.944\n",
      "test_correct:   0.8527\n",
      "----------------------------------------------------\n",
      "I:  290\n",
      "train_correct:  0.938\n",
      "test_correct:   0.8529\n",
      "----------------------------------------------------\n",
      "I:  300\n",
      "train_correct:  0.947\n",
      "test_correct:   0.8531\n",
      "----------------------------------------------------\n",
      "I:  310\n",
      "train_correct:  0.944\n",
      "test_correct:   0.8531\n",
      "----------------------------------------------------\n",
      "I:  320\n",
      "train_correct:  0.945\n",
      "test_correct:   0.8545\n",
      "----------------------------------------------------\n",
      "I:  330\n",
      "train_correct:  0.958\n",
      "test_correct:   0.854\n",
      "----------------------------------------------------\n",
      "I:  340\n",
      "train_correct:  0.95\n",
      "test_correct:   0.8541\n",
      "----------------------------------------------------\n",
      "I:  350\n",
      "train_correct:  0.954\n",
      "test_correct:   0.8543\n",
      "----------------------------------------------------\n",
      "I:  360\n",
      "train_correct:  0.947\n",
      "test_correct:   0.8537\n",
      "----------------------------------------------------\n",
      "I:  370\n",
      "train_correct:  0.951\n",
      "test_correct:   0.8537\n",
      "----------------------------------------------------\n",
      "I:  380\n",
      "train_correct:  0.957\n",
      "test_correct:   0.8542\n",
      "----------------------------------------------------\n",
      "I:  390\n",
      "train_correct:  0.954\n",
      "test_correct:   0.8532\n",
      "----------------------------------------------------\n",
      "I:  400\n",
      "train_correct:  0.957\n",
      "test_correct:   0.8545\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_im)):\n\u001b[0;32m     60\u001b[0m     layer_0 \u001b[38;5;241m=\u001b[39m test_im[i: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 61\u001b[0m     layer_1 \u001b[38;5;241m=\u001b[39m tanh(\u001b[43mlayer_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_0_1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     62\u001b[0m     layer_2 \u001b[38;5;241m=\u001b[39m layer_1\u001b[38;5;241m.\u001b[39mdot(weights_1_2)\n\u001b[0;32m     63\u001b[0m     test_correct_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(layer_2) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_lab[i: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = (x_train[:1000].reshape(1000, 28 * 28) / 255, y_train[:1000])\n",
    "\n",
    "temp = np.zeros((len(labels),10))\n",
    "for i, l in enumerate(labels):\n",
    "    temp[i][l] = 1\n",
    "labels = temp\n",
    "\n",
    "test_im = x_test.reshape(len(x_test), 28 * 28) / 255\n",
    "temp = np.zeros((len(test_im), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    temp[i][l] = 1\n",
    "test_lab = temp\n",
    "\n",
    "\n",
    "relu = lambda x: (x > 0) * x\n",
    "relu2deriv = lambda x: x > 0\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "alpha, pixels_per_image, hidden_size = (2, 28 * 28, 100)\n",
    "iterations, num_labels = (10000, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.02 * np.random.random((pixels_per_image, hidden_size)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_st, batch_end = ((i * batch_size), ((i + 1) * batch_size))#!!!!!!!\n",
    "        layer_0 = images[batch_st: batch_end]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k: k + 1]) == np.argmax(labels[batch_st + k: batch_st + k + 1]))\n",
    "        \n",
    "        layer_2_delta = (labels[batch_st: batch_end] - layer_2) / batch_size / layer_2.shape[0]#!!!!!!!!!!!!!\n",
    "#         print(layer_2_delta.shape, layer_2.shape)\n",
    "#         break\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "#     break\n",
    "    test_correct_cnt = 0\n",
    "    for i in range(len(test_im)):\n",
    "        layer_0 = test_im[i: i + 1]\n",
    "        layer_1 = tanh(layer_0.dot(weights_0_1))\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_lab[i: i + 1]))\n",
    "    \n",
    "    if j % 10 == 0:\n",
    "        print('I: ', j)\n",
    "        print('train_correct: ', correct_cnt / len(labels))\n",
    "        print('test_correct:  ', test_correct_cnt / len(test_lab))\n",
    "        print('----------------------------------------------------')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e085f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
